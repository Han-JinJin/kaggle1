2D部分
一、题目理解
有一堆古城卷轴的3D CT扫描图片，需要用算法精准找出图片中肉眼几乎看不见的墨水痕迹，输出墨水区域的位置（二值掩码），并按指定格式提交结果。CT把卷轴在Z轴方向切成 65 层。
目前训练集有3个卷轴数据带墨迹标注，相当于已知答案，可以用来让算法学习墨水特征，但是65层灰度图.tif并非所有的都有效，可以去掉深层无墨水和表层干扰多的部分，取中间部分的层数进行训练。模型是选定的，但是参数权重未知，通过训练集反复训练得到的指标确定最优模型参数，推理时复用预测墨迹位置。
原始数据是三维张量，Z 轴对应卷轴不同深度的扫描切片；含墨水像素正样本占比极低，且仅集中在少数 Z 层而非全深度，相邻 Z 层特征高度冗余；样本不均衡，需要模型聚焦局部深度范围内的微弱差异；仅3个训练片段， 过拟合风险极大；
二、2D-UNet（自制版得分0.10...后面引入开源模型预训练优化后0.418）
从65层中选择中间层数，将三维数据从中选择多层作为二维数据输入，用2D模型训练推理，更快一些。
（一）数据处理：
（1）数据加载时如果选择层数多，比如我第一次选了20层，一次性加载导致超出内存，所以添加了按需加载，避免占满内存（选择10以内层数就可以直接加载）过滤无效区域过mask.png筛选窗口，仅保留 mask.mean>0.1 的224×224窗口
（2）样本分类：遍历有效区域，通过墨水像素数量区分正/负样本
（3）数据增强，水平垂直翻转+亮度对比+平移旋转缩放+随机遮挡
（二）模型：
Attention UNet，构建带注意力机制和差异化Dropout的UNet，编码三层卷积池化下采样，在解码器上添加注意门，让模型主动聚焦墨水区域。
编码器：分 3 层（40→80→160 通道），每层用DoubleConv+MaxPool，配置轻量 Dropout（0.1）编码器负责提取基础特征，低Dropout保证特征提取的稳定性；
注意力门（AttentionGate 类）：解码器上采样后的特征作为信号，对编码器的跳跃连接特征做权重筛选（通过 Sigmoid 生成 0~1 的注意力权重，仅保留与墨水相关的特征，抑制背景噪声）；
解码器：分 3 层（320→160→80→40 通道），每层用Upsample+DoubleConv，配置更高 Dropout（0.15） —— 解码器负责还原特征尺寸，高 Dropout 防止过拟合（解码器更易学习到背景噪声）；
编码器特征──>（注意力门──>加权特征──> Concat）──>解码器──>解码器上采样
（三）损失函数：有点复杂的Focal Loss+Dice loss，为了解决正负样本类别不平衡，增加参数让模型少关注背景样本主要目的为了降低假阳性，聚焦比较难分析样本提高准确率，Dice loss来平衡召回率，但是后面发现没啥用，删掉了，用正常BCE损失函数解决下不平衡样本类别。
BCE(p,y)=−ylog(p)−(1−y)log(1−p)
FL(p,y)=−αy(1−p)γlog(p)−(1−α)(1−y)pγlog(1−p)
y是真实标签，p是输出概率（墨迹概率接近1）α正负样本权重，γ聚焦系数，观察检测指标（loss和acc换了几次选了个比较好的0.25，0.2。
（四）采样挖掘难例，强制模型学易误判的背景（第一次测试发现1值有点多加入的，引入开源成熟模型没有这样的问题就删掉了）
训练样本中大部分是背景，有痕迹的地方大部分是噪声，模型学不到墨水特征，且易误判背景为墨水，采样让模型重点学习非墨水但易误判的部分。
（1）难例池动态更新（HardNegativeSampler 类）
每轮训练前，随机采样部分负样本，输入模型计算背景区域被预测为墨水的损失；按损失值降序排序，取前40%的负样本作为难例负样本池（最容易误判的背景）强制模型关注易误判为墨水的背景学习
（五）训练验证
优化器配置：AdamW（权重衰减 3e-5），适配小批量训练的参数更新；
学习率调度：CosineAnnealingWarmRestarts，先预热再余弦退火；
由于只有三个fragment，两个训练一个验证训练数据会比较少，两个方案都试了下：
①　三个都训练，然后从中采样100个patch验证，训练轮数多了就多加点patch搜索合适的阈值，保存验证结果最好的模型用于推理。
②　12训练3验证，23训练1验证，132，后面三个模型都推理一遍求均值。
（2）训练循环
前向传播→损失计算→反向传播→难例更新
仅保存 F0.5 最高的模型权重，避免保存过拟合的模型。
（六）推理
①　加载训练模型权重→逐片段处理测试数据
②　滑动窗口调用模型预测（重叠部分取均值，加入TTA对张量做水平垂直翻转，分别预测后取均值）
③　高斯加权融合预测结果（窗口拼接的边缘部分更相信中心区域的预测标注）
④　后处理（二值化，阈值在训练时搜索优化；形态学开运算消除孤立的噪声）
⑤　RLE编码生成提交文件（将二值掩码转换成提交格式中的字符串）
三、引入标准开源模型预处理优化后0.418
用标准的开源Unet，编码器采用efficientnet-b0作为骨干网络，加载ImageNet 预训练权重。编码器用efficientnet-b0 作为骨干网络，加载 ImageNet 预训练权重，不需要Dropout 配置；解码器标准 UNet 解码器，仍加入注意力机制，直接拼接编码器的跳跃连接特征；损失函数用 SoftBCEWithLogitsLoss，带Sigmoid函数。前向传播→损失计算→反向传播→参数更新
图像切分成224×224大小的块储存坐标，滑动窗口调用训练好的模型权重预测，如果是选取训练方案二就是三次推理预测结果求平均。最后拼接小块结果，根据训练验证时筛选的阈值分化0，1二值。